
podman commit -a 'Danny' -c 'EXPOSE 80' -c 'ENTRYPOINT ["httpd"]' -c 'CMD ["-D","FOREGROUND"]' ee myweb:1.0

podman run -it registry...:latest /bin/bash

podman run -d -p 12345:80 -v /home/danny/website:/var/www/html myweb:1.0

github.com/sclorg/


sudo yum install -y nano
sudo yum install -y git

(nano is easier use vi)


dockerfile keywords
FROM
LABEL

EXPOSE
ENV

RUN
ADD
USER

ENTRYPOINT


podman build . -t myweb:20240625 --squash

podman login quay.io
podman push myweb:20240625 quay.io/siendut/myweb:20240625

podman images -a (will show also overwritten images)
(to delete image)
podman rmi ee

Powershell:
wsl --shutdown (to kill wsl, occupy 800 MB of physical disk space)


& crc oc-env | Invoke-Expression
oc login -u kubeadmin -p sMRko-BJsQt-AxJ9H-UcuJY https://api.crc.testing:6443

deployment stratey:
1. rolling update
2. recreate

2 entry point of OpenShift Cluster:
1. to access OpenShift Cluster API (all 3 out of 3 Master Nodes serve Cluster API)
api.<<clusterName>>.<<domainName>>.com:6443
2. to access Infra Node / Rout resource, need wildcard dns (2 out of 3 Master Nodes serve the Infra Node)
*.apps.<<clustrName>>.<<domainName>>.com

crc console

OpenShift assisted setup ->
1. go to OpenShift website, https://console.redhat.com/openshift/
2. Create Cluster > DataCenter > Assisted Clusters > ...
--download the Assisted installer cluster .iso file. vvv
3. run the iso inside the Virtual Machine.
4. follow the setup it will go through steps, just finish all the steps.
minimum CPU 4 (single node need 8) core RAM 16 GB DiskSpace 100 GB 

setup the network cluster of Master node with floating IP (fail over cluster)
download the .iso, go to each host, boot from CD room (the .iso image)


to check cluster ongoing log
oc get events -w


kel-ocp.com
https://console-openshift-console.apps.cluster.kel-ocp.com/
oc login -u danny -p redhat https://console-openshift-console.apps.cluster.kel-ocp.com/


oc completion powershell | Out-String | Invoke-Expression
(to enable oc <<tab>> auto completion command)

oc rsh myPodName
(to access shell terminal into the pod instance

oc create -f mypod.yaml
yaml file section configuration help:
oc explain po
oc explain pods.spec
oc explain pods.spec.containers


oc api-resources | findstr secret


oc new-app [--as-deployment-config] {[--docker-image] <IMAGE>}

servic (svc) naming convention internal cluster local domain
<<svc-name>>.<<proj-name>>.svc[.cluster.local]
oc expose svc/myweb
oc get route
svc expose naming convention:
<svcName>-<projName>.apps.cluster.kel-ocp.com
(by default it expose port 80)


oc expose svc myweb --name abc --hostname abc.def.ghi
add this line C:\Windows\System32\drivers\etc\host
34.142.169.1 abc.def.ghi


in kubernetes rout called Ingress


to browse shared image stream from internet
oc get is -n openshift

in case image don't provide db client in the db pod, can use oc port fowarding
oc port-forward --help

to set ENV variable using oc command via config map file
oc create cm mycm --from-literal HOST=mydb.danny-dbproj.svc --from-literal NAME=testdb --from-literal PASS=redhat
oc set env deploy/myapp --prefix DB_ --from cm/mycm
to unset env variable:
oc set env deploy/myapp DB_NAME- (<<envKey>>-)
or just edit the cm
oc edit cm/mycm


to retrigger build config rebuild
oc start-build bc/myapp

oc logs bc/myapp -f


to setup persistent volum storage
 oc set volume deploy/myapp --add --mount-path /opt/data --claim-class standard-csi --claim-size 10Mi --name myvol

to make persistnce volume not writing to same volume, use statefulset
this will make each pod having unique storage


to check role binding inside 1 project
oc describe rolebinding <<rolename>>
to check clucster scoped role binding
oc descrbe clusterrolebinding <<rolename>>


scc policy lab testing
 oc adm policy scc-subject-review deploy/abc
RESOURCE        ALLOWED BY
<unknown>/abc   anyuid
 oc adm policy add-scc-to-user anyuid -z mysa
this command is to update the servic account running the pod build
 oc set serviceaccount deploy/abc mysa



Certificates
login using cluster admin
oc get csr
oc adm certificate approve 12354-aasd234 223adf-afg23 ...
Self Signing Operator:
or, leave the VM on within 24 hour
the first certificate validity is 24 hour, after first renewal 1 month, subsequently 1 year
if VM off, need to sign the OAuth certificate manually
in kubeconfig file (difficult)
export KUBECONFIG=./kubeconfig
then oc get csr
then oc adm certificate approve ...




Firewall
cluster-admin need to create project Label
 oc label namespace danny-dbproj mynetwork=database [--overwrite]
 oc label namespace danny-webproj network=website
in case typo
oc label namespace danny-webproj network-
 oc label namespace danny-webproj mynetwork=website

firewall rule should be created using yaml file
ingress = incoming rule
egress = outcoming rule

 oc apply -f .\denyall.yaml
( oc apply same as oc create, but if already exist, it will update )



